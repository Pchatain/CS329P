{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "SusoCCTrUuRL",
    "outputId": "1db5a4f7-7589-4971-ee72-00eba5b678b0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/wenxindong/Desktop/Stanford/CS329P/project/riiid-test-answer-prediction\n",
      "\u001b[34mAutogluonModels\u001b[m\u001b[m/                       cv1_valid.pickle.zip\n",
      "cv1_train.pickle                       cv1_valid_100k.pickle\n",
      "cv1_train.pickle.zip                   example_sample_submission.csv\n",
      "cv1_train_10000k.pickle                example_test.csv\n",
      "cv1_train_10000k_preprocessed.pickle   lectures.csv\n",
      "cv1_train_1000k.pickle                 questions.csv\n",
      "cv1_train_1000k_preprocessed.pickle    riiid-test-answer-prediction.zip\n",
      "cv1_train_100k.pickle                  \u001b[34mriiideducation\u001b[m\u001b[m/\n",
      "cv1_train_100k_preprocessed.pickle     test_4920_users.pickle\n",
      "cv1_train_preprocessed.pickle          test_4920_users_preprocessed.pickle\n",
      "cv1_val_100k_preprocessed.pickle       train.csv\n",
      "cv1_val_10k.pickle                     train_39360_users.pickle\n",
      "cv1_val_10k_preprocessed.pickle        train_39360_users_preprocessed.pickle\n",
      "cv1_val_preprocessed.pickle            valid_4920_users.pickle\n",
      "cv1_valid.pickle                       valid_4920_users_preprocessed.pickle\n",
      "cpu\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "import torch\n",
    "%pwd\n",
    "%cd /Users/wenxindong/Desktop/Stanford/CS329P/project/riiid-test-answer-prediction\n",
    "%ls\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "id": "kKxXNu7VXJGS"
   },
   "outputs": [],
   "source": [
    "train_pickle = 'train_39360_users.pickle'  #about one tenth of the training dataset\n",
    "valid_pickle = 'test_4920_users.pickle'   # too lazy to change name to test_pickle\n",
    "question_file = 'questions.csv'\n",
    "lecture_file = 'lectures.csv'\n",
    "\n",
    "# Read data\n",
    "train = pd.read_pickle(train_pickle)\n",
    "valid = pd.read_pickle(valid_pickle)\n",
    "lectures = pd.read_csv(lecture_file)\n",
    "questions = pd.read_csv(question_file)\n",
    "#subsample\n",
    "train = train[:len(train)//10]\n",
    "valid = valid[:len(valid)//10]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "id": "lTJbwvciYmXI"
   },
   "outputs": [],
   "source": [
    "#Sort by time\n",
    "train = train.sort_values(by=['timestamp'])\n",
    "train = train.reset_index(drop=True)\n",
    "valid = valid.sort_values(by=['timestamp'])\n",
    "valid = valid.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "4m_s-oS-op4T",
    "outputId": "bb940f54-2806-4f2c-b9d5-82e5cbb88df2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# of Training Entries: 989400\n"
     ]
    }
   ],
   "source": [
    "train = train.drop(np.where(train['content_type_id'] == 1)[0], axis=0)\n",
    "train = train.reset_index(drop=True)\n",
    "print(\"# of Training Entries: \" + str(train.shape[0]))\n",
    "\n",
    "valid = valid.drop(np.where(valid['content_type_id'] == 1)[0], axis=0)\n",
    "valid = valid.reset_index(drop=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "id": "3bYw4qyugsag"
   },
   "outputs": [],
   "source": [
    "#This is to map question_id into parts (Note that if we also want to include the lecture part, we can do so by concatenating questions.csv with lectures.csv)\n",
    "train['part'] = np.array(questions['part'])[np.array(train['content_id'])]\n",
    "valid['part'] = np.array(questions['part'])[np.array(valid['content_id'])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "id": "c5AMkYqchBcV"
   },
   "outputs": [],
   "source": [
    "#Should run only one time\n",
    "train = train.drop(['row_id', 'content_id', 'content_type_id', 'task_container_id', 'user_answer', 'prior_question_elapsed_time', 'prior_question_had_explanation'], axis=1)\n",
    "\n",
    "#Sort lexiographically\n",
    "train = train.sort_values(by=['user_id', 'timestamp'])\n",
    "train = train.reset_index(drop=True)\n",
    "\n",
    "train = train.drop(['timestamp'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "id": "4_wm4OITc5X8"
   },
   "outputs": [],
   "source": [
    "#Should run only one time\n",
    "valid = valid.drop(['row_id', 'content_id', 'content_type_id', 'task_container_id', 'user_answer', 'prior_question_elapsed_time', 'prior_question_had_explanation'], axis=1)\n",
    "\n",
    "#Sort lexiographically\n",
    "valid = valid.sort_values(by=['user_id', 'timestamp'])\n",
    "valid = valid.reset_index(drop=True)\n",
    "\n",
    "valid = valid.drop(['timestamp'], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4ilnS1rvazLt"
   },
   "source": [
    "# Empirical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "88Lh0KB8N4Cq",
    "outputId": "79c39f9a-2efd-4c1f-e038-8adca7b6626f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training BKT model for part 1\n",
      "there are 76299 rows, 2806 students\n",
      "Training BCE losss: 0.545, acc: 0.761\n",
      "BCE losss: 0.582, acc: 0.732\n",
      "training BKT model for part 2\n",
      "there are 188335 rows, 3471 students\n",
      "Training BCE losss: 0.583, acc: 0.725\n",
      "BCE losss: 0.586, acc: 0.723\n",
      "training BKT model for part 3\n",
      "there are 87788 rows, 2009 students\n",
      "Training BCE losss: 0.577, acc: 0.724\n",
      "BCE losss: 0.566, acc: 0.734\n",
      "training BKT model for part 4\n",
      "there are 83160 rows, 1946 students\n",
      "Training BCE losss: 0.609, acc: 0.693\n",
      "BCE losss: 0.592, acc: 0.711\n",
      "training BKT model for part 5\n",
      "there are 396050 rows, 3750 students\n",
      "Training BCE losss: 0.650, acc: 0.639\n",
      "BCE losss: 0.656, acc: 0.630\n",
      "training BKT model for part 6\n",
      "there are 108879 rows, 1976 students\n",
      "Training BCE losss: 0.614, acc: 0.683\n",
      "BCE losss: 0.625, acc: 0.679\n",
      "training BKT model for part 7\n",
      "there are 48889 rows, 1815 students\n",
      "Training BCE losss: 0.589, acc: 0.711\n",
      "BCE losss: 0.578, acc: 0.727\n"
     ]
    }
   ],
   "source": [
    "def prep_data_BKT(data_df, part_id):\n",
    "  train0 = data_df[data_df['part']==part_id]\n",
    "  train0.reset_index(inplace=True)\n",
    "  map, counts = np.unique(train0['user_id'], return_counts=True)\n",
    "  cum_counts = np.cumsum(counts)\n",
    "  start_idxs = np.append(0, cum_counts)\n",
    "  return train0, start_idxs\n",
    "def evaluate_BKT(train0, C, P_L0, P_T, P_G, P_S, start_idxs):\n",
    "  #for every student\n",
    "  predictions = []\n",
    "  for i in range(len(start_idxs)-1):\n",
    "    L = P_L0\n",
    "    student_history = np.array(train0[\"answered_correctly\"][start_idxs[i]: start_idxs[i+1]])\n",
    "    for answer in student_history:\n",
    "      prediction = L*(1-P_S) + (1-L)*P_G\n",
    "      predictions.append(prediction)\n",
    "      P_L_obs= 0\n",
    "      if answer==1:\n",
    "        P_L_obs = (L*(1-P_S)) / (L*(1-P_S)+ (1-L)*P_G)\n",
    "      else:\n",
    "        P_L_obs = (L*(P_S)) / (L*(P_S)+ (1-L)*(1-P_G))\n",
    "      L = P_L_obs + (1-P_L_obs)*P_T\n",
    "  predictions = np.array(predictions)\n",
    "  # print(predictions)\n",
    "  # plt.scatter(C[np.where(C==1)]+np.where(C==1), predictions[np.where(C==1)], c = \"red\", s = 0.1)\n",
    "  # plt.scatter(C[np.where(C==0)]+np.where(C==0), predictions[np.where(C==0)], c = \"green\", s = 0.1)\n",
    "  # plt.show()\n",
    "  bce_loss = np.sum(- C*np.log(predictions) - (1-C)*np.log(1-predictions))/len(predictions)\n",
    "  acc = np.sum(C*(predictions>0.5) + (1-C)*(predictions<0.5))/len(predictions)\n",
    "  return bce_loss, acc, predictions\n",
    "\n",
    "def get_best_ki(student_history):\n",
    "    len_history = len(student_history)\n",
    "    total_ones = np.sum(student_history)\n",
    "    max_acc = 0\n",
    "    best_i = 0\n",
    "    num_mistakes_before = 0\n",
    "    num_correct_before = 0\n",
    "    for i in range(len_history+1):\n",
    "      #i = position of first green check \n",
    "      acc =num_mistakes_before + (total_ones - num_correct_before)\n",
    "      if acc>max_acc:\n",
    "        best_i  = i\n",
    "        max_acc = acc\n",
    "      if i<len_history and student_history[i] == 0:\n",
    "        num_mistakes_before+=1\n",
    "      if i<len_history and student_history[i] == 1:\n",
    "        num_correct_before+=1\n",
    "    return best_i\n",
    "\n",
    "def fit_BKT(train0, start_idxs):\n",
    "\n",
    "  K = []\n",
    "  for i in range(len(start_idxs)-1):\n",
    "    student_history = np.array(train0[\"answered_correctly\"][start_idxs[i]: start_idxs[i+1]])\n",
    "    best_i = get_best_ki(student_history)\n",
    "    student_ki = [0 for _ in range(best_i)] + [1 for _ in range(len(student_history) -  best_i)]\n",
    "    K.extend(student_ki)\n",
    "  \n",
    "  K = np.array(K)\n",
    "  C = np.array(train0[\"answered_correctly\"])\n",
    "  P_L0 = np.mean(K[start_idxs[:-1]])\n",
    "  P_T = np.sum(K[1:]*(1-K[:-1])) / np.sum((1-K[:-1]))\n",
    "  P_G = np.sum(C*(1-K)) / np.sum((1-K))\n",
    "  P_S = np.sum((1-C)*(K)) / np.sum((K))\n",
    "  return P_L0, P_T, P_G, P_S, C, K\n",
    "\n",
    "all_predictions = []\n",
    "all_targets = []\n",
    "for part in range(1,8):\n",
    "  print(\"training BKT model for part {}\".format(part))\n",
    "  #training\n",
    "  train0, start_idxs = prep_data_BKT(train, part)\n",
    "  print(\"there are {} rows, {} students\".format(len(train0), len(start_idxs)))\n",
    "  P_L0, P_T, P_G, P_S, C, K = fit_BKT(train0, start_idxs)\n",
    "  bce_loss, acc, predictions = evaluate_BKT(train0, C,  P_L0, P_T, P_G, P_S, start_idxs)\n",
    "  print(\"Training BCE losss: {:.3f}, acc: {:.3f}\".format(bce_loss, acc))  \n",
    "\n",
    "  #testing\n",
    "  valid0, start_idxs_valid = prep_data_BKT(valid, part)\n",
    "  _, _, _, _, C, _ = fit_BKT(valid0, start_idxs_valid)\n",
    "  bce_loss, acc, predictions = evaluate_BKT(valid0, C, P_L0, P_T, P_G, P_S, start_idxs_valid)\n",
    "  all_predictions.extend(predictions)\n",
    "  all_targets.extend(C)\n",
    "  print(\"BCE losss: {:.3f}, acc: {:.3f}\".format(bce_loss, acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "overall accuracy on the test set is 0.6721045417469034\n",
      "overall auc score is 0.6094982534491316\n"
     ]
    }
   ],
   "source": [
    "#calculate overall accuracy and AUC\n",
    "accuracy = np.sum((np.array(all_predictions) >0) +0 == np.array(all_targets)+0) / len(all_targets)\n",
    "print(f\"overall accuracy on the test set is {accuracy}\")\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "auc = roc_auc_score(all_targets, all_predictions)\n",
    "print(f\"overall auc score is {auc}\")"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "BKT.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
